.version 8.0
.target sm_80
.visible .entry vector_add_kernel(
    .param .u64 param9,
    .param .u64 param10,
    .param .u64 param11,
    .param .u64 param12
) {
    .reg .u32 %r6, %r26, %r24, %r17, %r27, %r11, %r32, %r4, %r8, %r23, %r5, %r9, %r20, %r22, %r7, %r35, %r21, %r36, %r12;
    .reg .u64 %rd3, %rd1, %rd28, %rd34, %rd14, %rd31, %rd2, %rd33, %rd15, %rd29, %rd0, %rd19, %rd18, %rd13, %rd30, %rd16;
    .reg .pred %p10, %p25;
    vector_add_kernel_start:
    ld.param.u64 %rd0, [param9];
    ld.param.u64 %rd1, [param10];
    ld.param.u64 %rd2, [param11];
    ld.param.u64 %rd3, [param12];
    block_1_start:
    mov.u32 %r4, %ntid.x;
    mov.u32 %r5, %ctaid.x;
    mul.lo.s32 %r6, %r4, %r5;
    mov.u32 %r7, %tid.x;
    add.s32 %r8, %r6, %r7;
    mov.u32 %r5, %r8;
    cvt.u32.u64 %r9, %rd3;
    setp.ge.u32 %p10, %r8, %r9;
    @%p10 bra block_1_end;
    mov.u32 %r11, 2;
    shl.b32 %r12, %r5, %r11;
    mov.u32 %r5, %r12;
    cvt.u64.u32 %rd13, %r12;
    add.s64 %rd14, %rd2, %rd13;
    cvt.u64.u32 %rd15, %r5;
    add.s64 %rd16, %rd1, %rd15;
    ld.global.u32 %r17, [%rd16];
    cvt.u64.u32 %rd18, %r5;
    add.s64 %rd19, %rd0, %rd18;
    ld.global.u32 %r20, [%rd19];
    add.s32 %r21, %r17, %r20;
    st.global.u32 [%rd14], %r21;
    block_1_end:
    mul.lo.s32 %r22, %r4, %r5;
    add.s32 %r23, %r22, %r7;
    mov.u32 %r5, %r23;
    cvt.u32.u64 %r24, %rd3;
    setp.ge.u32 %p25, %r23, %r24;
    @%p25 bra vector_add_kernel_end;
    mov.u32 %r26, 2;
    shl.b32 %r27, %r5, %r26;
    mov.u32 %r5, %r27;
    cvt.u64.u32 %rd28, %r27;
    add.s64 %rd29, %rd2, %rd28;
    cvt.u64.u32 %rd30, %r5;
    add.s64 %rd31, %rd1, %rd30;
    ld.global.u32 %r32, [%rd31];
    cvt.u64.u32 %rd33, %r5;
    add.s64 %rd34, %rd0, %rd33;
    ld.global.u32 %r35, [%rd34];
    add.s32 %r36, %r32, %r35;
    st.global.u32 [%rd29], %r36;
    vector_add_kernel_end:
}

.visible .entry vector_add_loop_kernel(
    .param .u64 param9,
    .param .u64 param10,
    .param .u64 param11,
    .param .u64 param12
) {
    .reg .u32 %r8, %r52, %r53, %r17, %r33, %r51, %r50, %r14, %r5, %r46, %r13, %r15, %r11, %r6, %r49, %r34, %r4, %r10, %r7, %r32, %r9, %r16, %r12, %r28, %r31, %r35;
    .reg .u64 %rd48, %rd42, %rd47, %rd1, %rd24, %rd44, %rd45, %rd3, %rd29, %rd26, %rd43, %rd2, %rd30, %rd27, %rd0, %rd25;
    .reg .f32 %f36, %f39, %f19, %f37, %f22, %f18, %f21, %f40;
    .reg .pred %p23, %p20, %p38, %p41;
    vector_add_loop_kernel_start:
    ld.param.u64 %rd0, [param9];
    ld.param.u64 %rd1, [param10];
    ld.param.u64 %rd2, [param11];
    ld.param.u64 %rd3, [param12];
    mov.u32 %r4, %ntid.x;
    mov.u32 %r5, %ntid.z;
    mul.lo.s32 %r6, %r4, %r5;
    mov.u32 %r7, %ntid.y;
    mul.lo.s32 %r8, %r6, %r7;
    mov.u32 %r7, %r8;
    mov.u32 %r9, 2;
    shl.b32 %r10, %r8, %r9;
    mov.u32 %r11, %r10;
    mov.u32 %r12, %ctaid.x;
    mul.lo.s32 %r13, %r4, %r12;
    mov.u32 %r14, %tid.x;
    add.s32 %r15, %r13, %r14;
    mov.u32 %r5, %r15;
    mov.u32 %r16, 2;
    shl.b32 %r17, %r15, %r16;
    mov.u32 %r4, %r17;
    loop_0_start:
    block_2_start:
    cvt.rn.f32.u64 %f18, %rd3;
    cvt.rn.f32.u32 %f19, %r5;
    setp.ltu.f32 %p20, %f19, %f18;
    @%p20 bra block_2_end;
    ret;
    block_2_end:
    cvt.rn.f32.u64 %f21, %rd3;
    cvt.rn.f32.u32 %f22, %r5;
    setp.ltu.f32 %p23, %f22, %f21;
    @%p23 bra loop_0_start;
    ret;
    cvt.u64.u32 %rd24, %r4;
    add.s64 %rd25, %rd2, %rd24;
    cvt.u64.u32 %rd26, %r4;
    add.s64 %rd27, %rd1, %rd26;
    ld.global.u32 %r28, [%rd27];
    cvt.u64.u32 %rd29, %r4;
    add.s64 %rd30, %rd0, %rd29;
    ld.global.u32 %r31, [%rd30];
    add.s32 %r32, %r28, %r31;
    st.global.u32 [%rd25], %r32;
    add.s32 %r34, %r4, %r33;
    mov.u32 %r4, %r34;
    add.s32 %r35, %r5, %r7;
    mov.u32 %r5, %r35;
    bra loop_0_start;
    loop_0_end:
    block_2_start:
    cvt.rn.f32.u64 %f36, %rd3;
    cvt.rn.f32.u32 %f37, %r5;
    setp.ltu.f32 %p38, %f37, %f36;
    @%p38 bra block_2_end;
    ret;
    block_2_end:
    cvt.rn.f32.u64 %f39, %rd3;
    cvt.rn.f32.u32 %f40, %r5;
    setp.ltu.f32 %p41, %f40, %f39;
    @%p41 bra vector_add_loop_kernel_end;
    ret;
    cvt.u64.u32 %rd42, %r4;
    add.s64 %rd43, %rd2, %rd42;
    cvt.u64.u32 %rd44, %r4;
    add.s64 %rd45, %rd1, %rd44;
    ld.global.u32 %r46, [%rd45];
    cvt.u64.u32 %rd47, %r4;
    add.s64 %rd48, %rd0, %rd47;
    ld.global.u32 %r49, [%rd48];
    add.s32 %r50, %r46, %r49;
    st.global.u32 [%rd43], %r50;
    add.s32 %r52, %r4, %r51;
    mov.u32 %r4, %r52;
    add.s32 %r53, %r5, %r7;
    mov.u32 %r5, %r53;
    bra vector_add_loop_kernel_end;
    vector_add_loop_kernel_end:
}

